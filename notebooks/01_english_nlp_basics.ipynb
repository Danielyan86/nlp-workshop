{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-26T00:51:28.838980Z",
     "start_time": "2025-01-26T00:51:26.971911Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Tokenization Results ===\n",
      "Token: \n",
      ", Lemma: \n",
      "\n",
      "Token: Apple, Lemma: Apple\n",
      "Token: Inc., Lemma: Inc.\n",
      "Token: is, Lemma: be\n",
      "Token: planning, Lemma: plan\n",
      "Token: to, Lemma: to\n",
      "Token: open, Lemma: open\n",
      "Token: a, Lemma: a\n",
      "Token: new, Lemma: new\n",
      "Token: store, Lemma: store\n",
      "Token: in, Lemma: in\n",
      "Token: New, Lemma: New\n",
      "Token: York, Lemma: York\n",
      "Token: City, Lemma: City\n",
      "Token: ., Lemma: .\n",
      "Token: \n",
      ", Lemma: \n",
      "\n",
      "Token: The, Lemma: the\n",
      "Token: company, Lemma: company\n",
      "Token: 's, Lemma: 's\n",
      "Token: CEO, Lemma: CEO\n",
      "Token: Tim, Lemma: Tim\n",
      "Token: Cook, Lemma: Cook\n",
      "Token: announced, Lemma: announce\n",
      "Token: this, Lemma: this\n",
      "Token: during, Lemma: during\n",
      "Token: the, Lemma: the\n",
      "Token: annual, Lemma: annual\n",
      "Token: meeting, Lemma: meeting\n",
      "Token: ., Lemma: .\n",
      "Token: \n",
      ", Lemma: \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "# Load English model\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "# Sample text\n",
    "text = \"\"\"\n",
    "Apple Inc. is planning to open a new store in New York City. \n",
    "The company's CEO Tim Cook announced this during the annual meeting.\n",
    "\"\"\"\n",
    "\n",
    "# Process text\n",
    "doc = nlp(text)\n",
    "\n",
    "# 1. Basic tokenization\n",
    "print(\"=== Tokenization Results ===\")\n",
    "for token in doc:\n",
    "    print(f\"Token: {token.text}, Lemma: {token.lemma_}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1c662bfed4fbaf62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== POS Tagging ===\n",
      "Token: \n",
      ", POS: SPACE\n",
      "Token: Apple, POS: PROPN\n",
      "Token: Inc., POS: PROPN\n",
      "Token: is, POS: AUX\n",
      "Token: planning, POS: VERB\n",
      "Token: to, POS: PART\n",
      "Token: open, POS: VERB\n",
      "Token: a, POS: DET\n",
      "Token: new, POS: ADJ\n",
      "Token: store, POS: NOUN\n",
      "Token: in, POS: ADP\n",
      "Token: New, POS: PROPN\n",
      "Token: York, POS: PROPN\n",
      "Token: City, POS: PROPN\n",
      "Token: ., POS: PUNCT\n",
      "Token: \n",
      ", POS: SPACE\n",
      "Token: The, POS: DET\n",
      "Token: company, POS: NOUN\n",
      "Token: 's, POS: PART\n",
      "Token: CEO, POS: PROPN\n",
      "Token: Tim, POS: PROPN\n",
      "Token: Cook, POS: PROPN\n",
      "Token: announced, POS: VERB\n",
      "Token: this, POS: PRON\n",
      "Token: during, POS: ADP\n",
      "Token: the, POS: DET\n",
      "Token: annual, POS: ADJ\n",
      "Token: meeting, POS: NOUN\n",
      "Token: ., POS: PUNCT\n",
      "Token: \n",
      ", POS: SPACE\n"
     ]
    }
   ],
   "source": [
    "# 2. Part-of-speech tagging\n",
    "print(\"\\n=== POS Tagging ===\")\n",
    "for token in doc:\n",
    "    print(f\"Token: {token.text}, POS: {token.pos_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d4850bbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Named Entity Recognition ===\n",
      "Entity: Apple Inc., Label: ORG\n",
      "Entity: New York City, Label: GPE\n",
      "Entity: Tim Cook, Label: PERSON\n",
      "Entity: annual, Label: DATE\n"
     ]
    }
   ],
   "source": [
    "# 3. Named Entity Recognition\n",
    "print(\"\\n=== Named Entity Recognition ===\")\n",
    "for ent in doc.ents:\n",
    "    print(f\"Entity: {ent.text}, Label: {ent.label_}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
